{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/jovyan/stage-f-10-police-shootings/data/out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(download_url, out_path):\n",
    "    import subprocess\n",
    "    import sys\n",
    "    import logging\n",
    "    \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas'])\n",
    "    \n",
    "    default_url = \"https://storage.googleapis.com/used-cars/shootings/shootings.csv\"\n",
    "    url = download_url if download_url.startswith(\"https://storage.googleapis\") else default_url\n",
    "    \n",
    "    subprocess.run([\"wget\", \"-O\", f\"{out_path}/shootings.csv\", url])\n",
    "    \n",
    "    print(\"File Downloaded\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_data(\"\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(out_path):\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn', 'imblearn'])\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import imblearn\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    import pandas as pd\n",
    "    from sklearn.utils import shuffle\n",
    "    import logging\n",
    "    import pickle\n",
    "    \n",
    "    \n",
    "    def pre_process(data, out_path, is_train=False):\n",
    "\n",
    "\n",
    "        cat_cols = ['state', 'arms_category', 'race']\n",
    "\n",
    "        onehot_encoding_columns = ['gender', 'signs_of_mental_illness', 'manner_of_death', 'body_camera']\n",
    "\n",
    "        data = pd.get_dummies(data, drop_first=True, columns=onehot_encoding_columns, prefix_sep='-')\n",
    "\n",
    "        if is_train:\n",
    "\n",
    "            state_encoder = LabelEncoder()\n",
    "            ac_encoder = LabelEncoder()\n",
    "            race_encoder = LabelEncoder()\n",
    "\n",
    "            cat_cols_encoders = [state_encoder, ac_encoder, race_encoder]\n",
    "\n",
    "            encoders = zip(cat_cols, cat_cols_encoders)\n",
    "\n",
    "            for column, encoder in encoders:\n",
    "\n",
    "                data[column] = encoder.fit_transform(data[column])\n",
    "\n",
    "                with open(f\"{out_path}/{column}_encoder.pkl\", \"wb\") as enc:\n",
    "                    pickle.dump(encoder, enc)\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            encoders_dict = {}\n",
    "            for col in cat_cols:\n",
    "\n",
    "                with open(f\"{out_path}/{col}_encoder.pkl\", \"rb\") as enc:\n",
    "                    encoders_dict[f\"{col}_encoder\"] = pickle.load(enc)\n",
    "\n",
    "\n",
    "            encoders = zip(cat_cols, encoders_dict.keys())\n",
    "\n",
    "            for col, encoder in encoders:\n",
    "                data[col] = encoders_dict[encoder].transform(data[col])\n",
    "\n",
    "\n",
    "        df_copy = data.copy()\n",
    "\n",
    "        df_copy = shuffle(df_copy)\n",
    "        features = df_copy.drop(columns=['name','date','label', 'id', 'armed', 'city', 'threat_level', 'flee' ])\n",
    "        target = df_copy['label']\n",
    "\n",
    "\n",
    "        # Oversampling the undersampled labels\n",
    "        if is_train:\n",
    "            smote = SMOTE(random_state=0)\n",
    "            X, y = smote.fit_sample(features, target)\n",
    "\n",
    "        else:\n",
    "            X, y = features, target\n",
    "\n",
    "        # converting ndarray to dataframe\n",
    "        X = pd.DataFrame(X, columns=features.columns)\n",
    "        y = pd.Series(y, name=target.name)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    \n",
    "        \n",
    "    def f(row):\n",
    "        \n",
    "        '''\n",
    "          Function that will be used to create the target column of two classes 1 and 0.\n",
    "          Where 1 represents the unjustified cases and 0 represents the just ones. \n",
    "          '''\n",
    "        if ((row['threat_level']=='undetermined' or row['threat_level']=='other') and (row['flee']=='Not fleeing')):\n",
    "            val = 1\n",
    "\n",
    "        else:\n",
    "            val = 0\n",
    "        return val\n",
    "    \n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "    data = pd.read_csv(f'{out_path}/shootings.csv')\n",
    "    data['label'] = data.apply(f, axis=1)\n",
    "    train, test = train_test_split(data, test_size=0.2, random_state=100)\n",
    "    \n",
    "    trainset = pre_process(train, out_path, is_train=True)\n",
    "    testset = pre_process(test, out_path)\n",
    "    \n",
    "    logging.info(f\"Training data count: {trainset[0].shape}\")\n",
    "    logging.info(f\"Testing data count: {testset[0].shape}\")\n",
    "    \n",
    "\n",
    "        \n",
    "    with open(f\"{out_path}/trainset.pkl\", \"wb\") as train:\n",
    "        pickle.dump(trainset, train)\n",
    "        \n",
    "    with open(f\"{out_path}/testset.pkl\", \"wb\") as test:\n",
    "        pickle.dump(testset, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning():\n",
    "    return \"Hyperparameters tuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_data(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(out_path, trainset, bucket_name, model_path):\n",
    "    \n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "    import json\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import joblib\n",
    "    \n",
    "    \n",
    "    with open(f\"{out_path}/{trainset}\", 'rb') as f:\n",
    "        preprocessed_data = pickle.load(f)\n",
    "        \n",
    "    features = preprocessed_data[0]\n",
    "    targets = preprocessed_data[1]\n",
    "    \n",
    "    lrc = LogisticRegression()\n",
    "    lrc.fit(features, targets)\n",
    "    \n",
    "    \n",
    "    with open(f'{out_path}/model.joblib', \"wb\") as model:\n",
    "        joblib.dump(lrc, model)\n",
    "\n",
    "\n",
    "        \n",
    "    return json.dumps({\"features\": features.values.tolist()})\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(output_dir, 'trainset.pkl', 'police-shootings', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(out_path, testset, model_name):\n",
    "    \n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import joblib\n",
    "    import logging\n",
    "    \n",
    "    with open(f\"{out_path}/{testset}\", 'rb') as f:\n",
    "        preprocessed_data = pickle.load(f)\n",
    "        \n",
    "    with open(f\"{out_path}/{model_name}\", 'rb') as f:\n",
    "        lrc = joblib.load(f)\n",
    "        \n",
    "    features = preprocessed_data[0]\n",
    "    targets = preprocessed_data[1]\n",
    "    \n",
    "    lrc_pred = lrc.predict_proba(features)\n",
    "    auc_score = roc_auc_score(targets, lrc_pred[:,1])\n",
    "    \n",
    "    print(\"AUC Score\", auc_score)\n",
    "    logging.info(f\"ROC Score: {auc_score}\")\n",
    "    \n",
    "    return features\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score 0.6045497280635986\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>state</th>\n",
       "      <th>arms_category</th>\n",
       "      <th>gender-M</th>\n",
       "      <th>signs_of_mental_illness-True</th>\n",
       "      <th>manner_of_death-shot and Tasered</th>\n",
       "      <th>body_camera-True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>34.0</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4558</th>\n",
       "      <td>35.0</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>61.0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4779</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>67.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>25.0</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>979 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  race  state  arms_category  gender-M  \\\n",
       "4720  34.0     5     34              3         1   \n",
       "917   30.0     4     47              8         1   \n",
       "4558  35.0     5     26              3         1   \n",
       "2609  61.0     5     25             10         1   \n",
       "1599  23.0     2      4              3         1   \n",
       "...    ...   ...    ...            ...       ...   \n",
       "4779  24.0     1     33              3         1   \n",
       "4746  67.0     5      9              3         1   \n",
       "3537  25.0     5     49              8         1   \n",
       "1709  28.0     1     22              3         1   \n",
       "1731  24.0     2     10             10         1   \n",
       "\n",
       "      signs_of_mental_illness-True  manner_of_death-shot and Tasered  \\\n",
       "4720                             1                                 0   \n",
       "917                              0                                 0   \n",
       "4558                             0                                 0   \n",
       "2609                             0                                 0   \n",
       "1599                             0                                 0   \n",
       "...                            ...                               ...   \n",
       "4779                             0                                 0   \n",
       "4746                             0                                 0   \n",
       "3537                             0                                 0   \n",
       "1709                             0                                 0   \n",
       "1731                             0                                 0   \n",
       "\n",
       "      body_camera-True  \n",
       "4720                 0  \n",
       "917                  0  \n",
       "4558                 0  \n",
       "2609                 0  \n",
       "1599                 0  \n",
       "...                ...  \n",
       "4779                 1  \n",
       "4746                 0  \n",
       "3537                 0  \n",
       "1709                 1  \n",
       "1731                 0  \n",
       "\n",
       "[979 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(output_dir, 'testset.pkl', 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload(out_path, bucket_name):\n",
    "    import os\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'google-cloud-storage'])\n",
    "    from google.cloud import storage\n",
    "\n",
    "    def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "        \"\"\"Uploads a file to gcp bucket.\"\"\"\n",
    "        bucket_name = bucket_name\n",
    "        source_file_name = source_file_name\n",
    "        destination_blob_name = destination_blob_name\n",
    "\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "        blob.upload_from_filename(source_file_name)\n",
    "\n",
    "        print(\n",
    "            \"File {} uploaded to {}.\".format(\n",
    "                source_file_name, destination_blob_name\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    os.chdir(out_path)\n",
    "    files = os.listdir()\n",
    "    for file in files:\n",
    "        if 'set' not in file:\n",
    "            if 'pkl' in file:\n",
    "                upload_blob(bucket_name, f'{file}', f'encoders/{file}')\n",
    "            elif 'joblib' in file:\n",
    "                upload_blob(bucket_name, f'{file}', f'model/{file}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload(output_dir, 'police-shootings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "import kfp.components as comp\n",
    "from string import Template\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_op = comp.func_to_container_op(get_data, base_image=\"python:3.7\")\n",
    "\n",
    "preprocess_op = comp.func_to_container_op(preprocess, base_image=\"python:3.7-slim\")\n",
    "\n",
    "tuning_op = comp.func_to_container_op(hyperparameter_tuning, base_image=\"python:3.7-slim\")\n",
    "\n",
    "train_op = comp.func_to_container_op(train, base_image=\"python:3.7-slim\")\n",
    "\n",
    "validate_op = comp.func_to_container_op(test, base_image=\"python:3.7-slim\")\n",
    "\n",
    "upload_op = comp.func_to_container_op(upload, base_image=\"python:3.7-slim\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Police Shootings Sales Justification Pipeline\",\n",
    "    description=\"A Machine Learning Pipeline for determining police shootings justification\"\n",
    ")\n",
    "\n",
    "def police_shootings_pipeline(\n",
    "    out_path=\"/mnt\",\n",
    "    trainset=\"trainset.pkl\",\n",
    "    testset=\"testset.pkl\",\n",
    "    model_name=\"model.joblib\",\n",
    "    bucket_name=\"used-cars\",\n",
    "    model_path=\"model\",\n",
    "    download_url=\" \",\n",
    "    serving_name=\"my-ps-serving\",\n",
    "    serving_namespace=\"kubeflow\",\n",
    "    serving_export_dir=\"gs://used-cars/model\",\n",
    "    transform_image=\"gcr.io/kubeflow-292422/police-shootings-processing:latest\"\n",
    "    \n",
    "):\n",
    "    \n",
    "    volume_op = dsl.VolumeOp(\n",
    "        name=\"volume\",\n",
    "        resource_name=\"data-volume\",\n",
    "        size=\"2Gi\",\n",
    "        modes=dsl.VOLUME_MODE_RWO)\n",
    "    \n",
    "    download = download_op(download_url, out_path).add_pvolumes({out_path: volume_op.volume})\n",
    "    \n",
    "    preprocess = preprocess_op(out_path).add_pvolumes({out_path: download.pvolume})\n",
    "    \n",
    "    hyperparameter_tuning = tuning_op().add_pvolumes({out_path: preprocess.pvolume})\n",
    "    \n",
    "    train = train_op(out_path, trainset, bucket_name, model_path).add_pvolumes({out_path: hyperparameter_tuning.pvolume})\n",
    "    \n",
    "    validate = validate_op(out_path, testset, model_name).add_pvolumes({out_path: train.pvolume})\n",
    "    \n",
    "    upload = upload_op(out_path, bucket_name).add_pvolumes({out_path: validate.pvolume})\n",
    "    \n",
    "    \n",
    "    \n",
    "#     kfserving_template = Template(\n",
    "#         \"\"\"\n",
    "#             {\n",
    "#                   \"apiVersion\": \"serving.kubeflow.org/v1alpha2\",\n",
    "#                   \"kind\": \"InferenceService\",\n",
    "#                   \"metadata\": {\n",
    "#                     \"labels\": {\n",
    "#                       \"controller-tools.k8s.io\": \"1.0\"\n",
    "#                     },\n",
    "#                     \"name\": \"$name\",\n",
    "#                     \"namespace\": \"$namespace\"\n",
    "#                   },\n",
    "#                   \"spec\": {\n",
    "#                     \"default\": {\n",
    "#                       \"predictor\": {\n",
    "#                         \"minReplicas\": 1,\n",
    "#                         \"serviceAccountName\": \"kf-user\",\n",
    "#                         \"custom\": {\n",
    "#                             \"container\": {\n",
    "#                                 \"name\": \"predictor\",\n",
    "#                                 \"image\": \"$transformer\",\n",
    "#                                 \"command\": \n",
    "#                             }\n",
    "#                         }\n",
    "#                       }\n",
    "#                     }\n",
    "#                   }\n",
    "#         }\n",
    "#         \"\"\"\n",
    "#     )\n",
    "    \n",
    "#     kfservingjson = kfserving_template.substitute({'name': str(serving_name),\n",
    "#                                                   'namespace': str(serving_namespace),\n",
    "#                                                   'bucket': str(serving_export_dir),\n",
    "#                                                   'transformer': str(transform_image)})\n",
    "    \n",
    "#     kfservingdeployment = json.loads(kfservingjson)\n",
    "    \n",
    "#     serve = dsl.ResourceOp(\n",
    "#         name=\"serve\",\n",
    "#         k8s_resource=kfservingdeployment,\n",
    "#         action=\"apply\",\n",
    "#         success_condition=\"status.url\"\n",
    "#     )\n",
    "    \n",
    "#     (\n",
    "#         serve\n",
    "#         .after(test)\n",
    "#         .add_volume({out_path: test.pvolume})\n",
    "#     )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = police_shootings_pipeline\n",
    "experiment_name = 'used-cars-training'\n",
    "run_name = 'used-cars-pipeline run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUT_PATH = '/mnt',\n",
    "# TRAINSET = 'trainset.pkl',\n",
    "# TESTSET = 'testset.pkl',\n",
    "# MODEL_URI = '/tmp/export',\n",
    "# DOWNLOAD_URL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# arguments = {\n",
    "#     \"out_path\": OUT_PATH,\n",
    "#     \"trainset\": TRAINSET,\n",
    "#     \"testset\": TESTSET,\n",
    "#     \"model_uri\": MODEL_URI,\n",
    "#     \"download_url\": DOWNLOAD_URL,\n",
    "# }\n",
    "\n",
    "kfp.compiler.Compiler().compile(pipeline_func, f'{experiment_name}.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/cd18f857-18d8-4970-9c0d-61a58ab99c30\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/cc6be257-7098-4d18-8ab8-b519b3b3676f\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "\n",
    "run_result = client.create_run_from_pipeline_func(pipeline_func,\n",
    "                                                    experiment_name=experiment_name,\n",
    "                                                    run_name=run_name,\n",
    "                                                    arguments={}\n",
    "                                                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
